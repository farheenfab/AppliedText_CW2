{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Embedding, Dense\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: lowercase, stopwords, lemmatization\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# If saved as an HDF5 file\n",
    "model = load_model('bilstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# remove emptyrecords\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mdropna()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mReview\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mReview\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(preprocess_text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mReview\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m y \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39moverall\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4780\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4781\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4787\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4788\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4789\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4790\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4791\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4906\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4907\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4908\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4909\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   4910\u001b[0m         func,\n\u001b[1;32m   4911\u001b[0m         convert_dtype\u001b[39m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4912\u001b[0m         by_row\u001b[39m=\u001b[39mby_row,\n\u001b[1;32m   4913\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m   4914\u001b[0m         kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m-> 4915\u001b[0m     )\u001b[39m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[39m=\u001b[39mcurried, na_action\u001b[39m=\u001b[39maction, convert\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39mna_action, convert\u001b[39m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(values, mapper, convert\u001b[39m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_text\u001b[39m(text):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mlower()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     tokens \u001b[39m=\u001b[39m word_tokenize(text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     stop_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/something.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     tokens \u001b[39m=\u001b[39m [word \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop_words]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py:130\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m     token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m--> 131\u001b[0m     token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/destructive.py:181\u001b[0m, in \u001b[0;36mNLTKWordTokenizer.tokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    178\u001b[0m     text \u001b[39m=\u001b[39m regexp\u001b[39m.\u001b[39msub(substitution, text)\n\u001b[1;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m regexp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCONTRACTIONS2:\n\u001b[0;32m--> 181\u001b[0m     text \u001b[39m=\u001b[39m regexp\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m1 \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2 \u001b[39m\u001b[39m\"\u001b[39m, text)\n\u001b[1;32m    182\u001b[0m \u001b[39mfor\u001b[39;00m regexp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCONTRACTIONS3:\n\u001b[1;32m    183\u001b[0m     text \u001b[39m=\u001b[39m regexp\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m1 \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2 \u001b[39m\u001b[39m\"\u001b[39m, text)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('train.csv')  \n",
    "# remove emptyrecords\n",
    "data = data.dropna()\n",
    "\n",
    "data['Review'] = data['Review'].apply(preprocess_text)\n",
    "\n",
    "X = data['Review']\n",
    "y = data['overall'].values - 1\n",
    "\n",
    "# tokenization and padding\n",
    "embedding_dim = 100\n",
    "max_len = 100\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_len, padding='post')\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3864/3864 [==============================] - 61s 16ms/step\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SequenceNotStr' from 'pandas._typing' (/Users/fayazbadubhai/anaconda3/lib/python3.11/site-packages/pandas/_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/AmazonReviews.ipynb Cell 135\u001b[0m line \u001b[0;36m1\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/AmazonReviews.ipynb#Y255sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m predicted_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(test_predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/AmazonReviews.ipynb#Y255sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m submission_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mReview\u001b[39m\u001b[39m'\u001b[39m: test_data[\u001b[39m'\u001b[39m\u001b[39mReview\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mPredicted\u001b[39m\u001b[39m'\u001b[39m: predicted_labels \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m}) \n",
      "\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fayazbadubhai/Documents/GitHub/AppliedText_CW2/AmazonReviews.ipynb#Y255sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m submission_df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39msmote_lstm.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n",
      "\u001b[1;32m   3740\u001b[0m \u001b[39m@overload\u001b[39m\n",
      "\u001b[1;32m   3741\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_csv\u001b[39m(\n",
      "\u001b[1;32m   3742\u001b[0m     \u001b[39mself\u001b[39m,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   3763\u001b[0m     storage_options: StorageOptions \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3764\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n",
      "\u001b[1;32m   3765\u001b[0m     \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\n",
      "\u001b[1;32m   3767\u001b[0m \u001b[39m@overload\u001b[39m\n",
      "\u001b[1;32m   3768\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_csv\u001b[39m(\n",
      "\u001b[1;32m   3769\u001b[0m     \u001b[39mself\u001b[39m,\n",
      "\u001b[1;32m   3770\u001b[0m     path_or_buf: FilePath \u001b[39m|\u001b[39m WriteBuffer[\u001b[39mbytes\u001b[39m] \u001b[39m|\u001b[39m WriteBuffer[\u001b[39mstr\u001b[39m],\n",
      "\u001b[1;32m   3771\u001b[0m     sep: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[0;32m-> 3772\u001b[0m     na_rep: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3773\u001b[0m     float_format: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m Callable \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3774\u001b[0m     columns: Sequence[Hashable] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3775\u001b[0m     header: bool_t \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3776\u001b[0m     index: bool_t \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3777\u001b[0m     index_label: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3778\u001b[0m     mode: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3779\u001b[0m     encoding: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3780\u001b[0m     compression: CompressionOptions \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3781\u001b[0m     quoting: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3782\u001b[0m     quotechar: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3783\u001b[0m     lineterminator: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3784\u001b[0m     chunksize: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3785\u001b[0m     date_format: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3786\u001b[0m     doublequote: bool_t \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3787\u001b[0m     escapechar: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3788\u001b[0m     decimal: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3789\u001b[0m     errors: OpenFileErrors \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3790\u001b[0m     storage_options: StorageOptions \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n",
      "\u001b[1;32m   3791\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m   3792\u001b[0m     \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\n",
      "\u001b[1;32m   3794\u001b[0m \u001b[39m@final\u001b[39m\n",
      "\u001b[1;32m   3795\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(\n",
      "\u001b[1;32m   3796\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m3.0\u001b[39m\u001b[39m\"\u001b[39m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpath_or_buf\u001b[39m\u001b[39m\"\u001b[39m], name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mto_csv\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   3824\u001b[0m     storage_options: StorageOptions \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n",
      "\u001b[1;32m   3825\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/format.py:1159\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n",
      "\u001b[1;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m digits \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m   1145\u001b[0m     digits \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mdisplay.precision\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m   1147\u001b[0m fmt_obj \u001b[39m=\u001b[39m fmt_klass(\n",
      "\u001b[1;32m   1148\u001b[0m     values,\n",
      "\u001b[1;32m   1149\u001b[0m     digits\u001b[39m=\u001b[39mdigits,\n",
      "\u001b[1;32m   1150\u001b[0m     na_rep\u001b[39m=\u001b[39mna_rep,\n",
      "\u001b[1;32m   1151\u001b[0m     float_format\u001b[39m=\u001b[39mfloat_format,\n",
      "\u001b[1;32m   1152\u001b[0m     formatter\u001b[39m=\u001b[39mformatter,\n",
      "\u001b[1;32m   1153\u001b[0m     space\u001b[39m=\u001b[39mspace,\n",
      "\u001b[1;32m   1154\u001b[0m     justify\u001b[39m=\u001b[39mjustify,\n",
      "\u001b[1;32m   1155\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n",
      "\u001b[1;32m   1156\u001b[0m     leading_space\u001b[39m=\u001b[39mleading_space,\n",
      "\u001b[1;32m   1157\u001b[0m     quoting\u001b[39m=\u001b[39mquoting,\n",
      "\u001b[1;32m   1158\u001b[0m     fallback_formatter\u001b[39m=\u001b[39mfallback_formatter,\n",
      "\u001b[0;32m-> 1159\u001b[0m )\n",
      "\u001b[1;32m   1161\u001b[0m \u001b[39mreturn\u001b[39;00m fmt_obj\u001b[39m.\u001b[39mget_result()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:24\u001b[0m\n",
      "\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m writers \u001b[39mas\u001b[39;00m libwriters\n",
      "\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m SequenceNotStr\n",
      "\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_decorators\u001b[39;00m \u001b[39mimport\u001b[39;00m cache_readonly\n",
      "\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n",
      "\u001b[1;32m     28\u001b[0m     ABCDatetimeIndex,\n",
      "\u001b[1;32m     29\u001b[0m     ABCIndex,\n",
      "\u001b[1;32m     30\u001b[0m     ABCMultiIndex,\n",
      "\u001b[1;32m     31\u001b[0m     ABCPeriodIndex,\n",
      "\u001b[1;32m     32\u001b[0m )\n",
      "\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SequenceNotStr' from 'pandas._typing' (/Users/fayazbadubhai/anaconda3/lib/python3.11/site-packages/pandas/_typing.py)"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv') \n",
    "test_data = test_data.dropna()\n",
    "\n",
    "test_data['Review'] = test_data['Review'].apply(preprocess_text)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['Review'])\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "test_predictions = model.predict(test_padded)\n",
    "predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "submission_df = pd.DataFrame({'Review': test_data['Review'], 'Predicted': predicted_labels + 1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('smote_lstm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
